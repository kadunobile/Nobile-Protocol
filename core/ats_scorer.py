"""
Sistema de Pontua√ß√£o ATS (Applicant Tracking System) - v4.0.

v4.0: An√°lise contextual via LLM (GPT-4o) com fallback TF-IDF.
- Quando OpenAI client dispon√≠vel: an√°lise sem√¢ntica inteligente
- Quando offline: TF-IDF + Cosine Similarity (v3.2)

v3.2 (fallback):
- TF-IDF + Cosine Similarity com stopwords NLTK (PT/EN) + termos customizados
- Prompt da JD focado em termos t√©cnicos, ferramentas e siglas
- Filtro de n-grams gen√©ricos nos gaps e pontos fortes

Retorna: Score + Pontos Fortes + Gaps + Plano de A√ß√£o.
"""

import re
import json
import logging
from typing import Dict, Optional, List

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import nltk

# Garantir download dos stopwords na primeira execu√ß√£o
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords', quiet=True)

from nltk.corpus import stopwords

from core.utils import chamar_gpt

logger = logging.getLogger(__name__)

# ‚îÄ‚îÄ‚îÄ STOPWORDS: NLTK (PT + EN) + Termos customizados de CV/JD ‚îÄ‚îÄ‚îÄ
# Base robusta do NLTK (~400 stopwords PT + EN)
_nltk_stops = set(stopwords.words('portuguese')).union(set(stopwords.words('english')))

# Termos customizados espec√≠ficos de CV e Job Descriptions
_custom_stops = {
    # ‚îÄ‚îÄ‚îÄ VERBOS GEN√âRICOS DE JD (aparecem em QUALQUER vaga) ‚îÄ‚îÄ‚îÄ
    'desenvolver', 'gerenciar', 'impulsionar', 'otimizar', 'garantir', 'implementar',
    'coordenar', 'supervisionar', 'elaborar', 'executar', 'planejar', 'monitorar',
    'acompanhar', 'realizar', 'conduzir', 'promover', 'apoiar', 'contribuir',
    'participar', 'atuar', 'assegurar', 'propor', 'definir', 'estabelecer',
    'manter', 'identificar', 'analisar', 'avaliar', 'gerir', 'liderar',
    'orientar', 'direcionar', 'facilitar', 'viabilizar', 'fomentar',
    'aprimorar', 'estruturar', 'organizar', 'controlar', 'reportar',
    'comunicar', 'interagir', 'colaborar', 'integrar', 'alinhar',
    'priorizar', 'delegar', 'negociar', 'articular', 'mapear',
    'diagnosticar', 'solucionar', 'resolver', 'mitigar', 'prevenir',
    'develop', 'manage', 'drive', 'optimize', 'ensure', 'implement',
    'coordinate', 'supervise', 'execute', 'plan', 'monitor',
    'track', 'conduct', 'promote', 'support', 'contribute',
    'participate', 'maintain', 'identify', 'analyze', 'evaluate',
    'lead', 'guide', 'direct', 'facilitate', 'foster',
    'enhance', 'structure', 'organize', 'control', 'report',
    'communicate', 'collaborate', 'integrate', 'align', 'prioritize',
    'delegate', 'negotiate', 'deliver', 'build', 'create', 'design',
    'establish', 'provide', 'work', 'handle', 'oversee', 'prepare',
    # ‚îÄ‚îÄ‚îÄ PALAVRAS GEN√âRICAS DE JD / CV ‚îÄ‚îÄ‚îÄ
    'empresa', '√°rea', 'equipe', 'time', 'profissional', 'candidato',
    'experi√™ncia', 'conhecimento', 'habilidade', 'capacidade', 'compet√™ncia',
    'respons√°vel', 'responsabilidade', 'atividade', 'atividades', 'fun√ß√£o',
    'objetivo', 'resultado', 'resultados', 'processo', 'processos',
    'projeto', 'projetos', 'solu√ß√£o', 'solu√ß√µes', 'estrat√©gia', 'estrat√©gias',
    'n√≠vel', 'alto', 'alta', 'forte', 'fortes', 's√≥lida', 's√≥lido',
    'bom', 'boa', 'bons', 'boas', 'excelente', 'excelentes',
    'desej√°vel', 'desej√°veis', 'necess√°rio', 'necess√°ria', 'obrigat√≥rio', 'obrigat√≥ria',
    'diferencial', 'diferenciais', 'requisito', 'requisitos',
    'm√≠nimo', 'm√≠nima', 'anos', 'ano', 'superior', 'completo', 'completa',
    'gradua√ß√£o', 'forma√ß√£o', 'p√≥s', 'curso', 'cursos',
    'trabalho', 'mercado', 'neg√≥cio', 'neg√≥cios', 'cliente', 'clientes',
    'interno', 'interna', 'internos', 'internas', 'externo', 'externa',
    'relacionamento', 'relacionamentos', 'parceiro', 'parceiros',
    'demanda', 'demandas', 'necessidade', 'necessidades',
    'oportunidade', 'oportunidades', 'melhoria', 'melhorias',
    'indicador', 'indicadores', 'meta', 'metas',
    'relat√≥rio', 'relat√≥rios', 'report', 'reports',
    'reuni√£o', 'reuni√µes', 'apresenta√ß√£o', 'apresenta√ß√µes',
    'prazo', 'prazos', 'entrega', 'entregas',
    'qualidade', 'efici√™ncia', 'produtividade',
    'inova√ß√£o', 'transforma√ß√£o', 'crescimento',
    'vis√£o', 'miss√£o', 'valor', 'valores', 'cultura',
    'based', 'ability', 'skills', 'skill', 'experience', 'knowledge',
    'team', 'company', 'business', 'role', 'position',
    'responsible', 'required', 'preferred', 'minimum', 'years',
    'strong', 'excellent', 'good', 'proven', 'relevant',
    'including', 'related', 'across', 'within', 'using',
    'new', 'key', 'high', 'level', 'well',
    # ‚îÄ‚îÄ‚îÄ TERMOS DE CV (endere√ßo, meses, etc.) ‚îÄ‚îÄ‚îÄ
    'cargo', 'janeiro', 'fevereiro', 'mar√ßo', 'abril',
    'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro',
    'novembro', 'dezembro', 'jan', 'fev', 'mar', 'abr', 'mai', 'jun',
    'jul', 'ago', 'set', 'out', 'nov', 'dez',
    'paulo', 's√£o', 'rio', 'brasil', 'br', 'rua', 'apto', 'cep',
    'presente', 'atual', 'atualmente',
    # ‚îÄ‚îÄ‚îÄ CONECTORES E TERMOS VAZIOS ‚îÄ‚îÄ‚îÄ
    'al√©m', 'disso', 'assim', 'ainda', 'sobre', 'cada', 'todo', 'toda',
    'todos', 'todas', 'outro', 'outra', 'outros', 'outras',
    'onde', 'aqui', 'ali', 'l√°', 'ent√£o', 'portanto', 'por√©m',
    'contudo', 'entretanto', 'todavia', 'pois', 'porque', 'embora',
    'caso', 'conforme', 'segundo', 'atrav√©s', 'meio', 'forma',
    'modo', 'tipo', 'parte', 'fim', 'base', 'dia', 'vez',
    'vezes', 'bem', 'mal', 'demais', 'menos', 'tanto',
    'quanto', 'tal', 'tais', 'apenas', 'somente',
    'principalmente', 'especialmente', 'geralmente', 'normalmente',
    'diretamente', 'indiretamente', 'constantemente', 'continuamente',
    'relacionadas', 'relacionados', 'relacionada', 'relacionado',
    'adequada', 'adequado', 'adequadas', 'adequados',
    'efetiva', 'efetivo', 'efetivas', 'efetivos',
}

# Combinar: NLTK base (~400) + Custom (~150) = ~550+ stopwords
STOPWORDS_PT_EN = list(_nltk_stops.union(_custom_stops))

# ‚îÄ‚îÄ‚îÄ Termos gen√©ricos que nunca devem aparecer como gap ‚îÄ‚îÄ‚îÄ
_termos_genericos_gap = {
    'certified', 'certification', 'certificate',
    'qualified', 'qualification',
    'senior', 'junior', 'pleno', 's√™nior', 'j√∫nior',
    'manager', 'lead', 'head', 'director', 'chief',
    'gerente', 'coordenador', 'analista', 'especialista',
    'supervisor', 'diretor', 'l√≠der',
    'six', 'sigma',
    'proficiency', 'proficient', 'fluent', 'fluency',
    'operations', 'opera√ß√µes', 'revenue', 'receita',
    'engineer', 'engenheiro', 'developer', 'desenvolvedor', 'software',
    'analyst', 'consultor', 'consultant',
}


def _limpar_texto(texto: str) -> str:
    """Padroniza o texto para an√°lise."""
    texto = str(texto).lower()
    texto = re.sub(r'[^\w\s]', '', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto


def _analisar_compatibilidade(cv_texto: str, vaga_texto: str) -> Dict:
    """
    Executa an√°lise completa: Score + Gaps + Pontos Fortes + Plano de A√ß√£o.
    
    Cria uma NOVA inst√¢ncia do TfidfVectorizer a cada chamada.
    
    Args:
        cv_texto: Texto completo do CV
        vaga_texto: Job Description para compara√ß√£o
        
    Returns:
        Dict com score, pontos_fortes, gaps_identificados, plano_acao
    """
    cv_limpo = _limpar_texto(cv_texto)
    vaga_limpa = _limpar_texto(vaga_texto)
    
    if not cv_limpo or not vaga_limpa:
        logger.warning("CV ou JD vazio ap√≥s limpeza")
        return {
            "score": 0.0,
            "pontos_fortes": [],
            "gaps_identificados": [],
            "plano_acao": ["‚ùå Texto insuficiente para an√°lise."]
        }
    
    try:
        vectorizer = TfidfVectorizer(
            stop_words=STOPWORDS_PT_EN,
            ngram_range=(1, 3),
            min_df=1
        )
        
        tfidf_matrix = vectorizer.fit_transform([cv_limpo, vaga_limpa])
        feature_names = vectorizer.get_feature_names_out()
        
    except ValueError as e:
        logger.error(f"Erro na vetoriza√ß√£o: {e}")
        return {
            "score": 0.0,
            "pontos_fortes": [],
            "gaps_identificados": [],
            "plano_acao": ["‚ùå Texto insuficiente para an√°lise."]
        }
    
    # Score (Cosine Similarity)
    raw_similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
    
    # Escalar para faixa realista
    if raw_similarity <= 0.0:
        score_final = 0.0
    elif raw_similarity >= 0.35:
        score_final = 95.0
    else:
        score_final = (raw_similarity / 0.35) * 90.0 + 5.0
    
    score_final = round(score_final, 1)
    
    logger.debug(f"Raw similarity: {raw_similarity:.4f}, Scaled score: {score_final}")
    logger.debug(f"Vocabul√°rio: {len(feature_names)} termos (ap√≥s stopwords)")
    
    # An√°lise de termos
    dense = tfidf_matrix.todense()
    lista_cv = dense[0].tolist()[0]
    lista_vaga = dense[1].tolist()[0]
    
    df_analise = pd.DataFrame({
        'termo': feature_names,
        'peso_vaga': lista_vaga,
        'peso_cv': lista_cv
    })
    
    # Gaps: termos da vaga que N√ÉO est√£o no CV
    termos_faltantes_raw = df_analise[
        (df_analise['peso_vaga'] > 0) & (df_analise['peso_cv'] == 0)
    ].sort_values(by='peso_vaga', ascending=False)
    
    # Filtrar: remover termos gen√©ricos e n-grams que s√£o apenas t√≠tulos de cargo
    def _is_generic_term(termo: str) -> bool:
        """Verifica se um termo deve ser filtrado dos gaps."""
        # Remover siglas muito curtas
        if len(termo) <= 2:
            return True
        
        # Remover se √© termo gen√©rico standalone
        if termo in _termos_genericos_gap:
            return True
        
        # Remover n-grams que cont√™m palavras gen√©ricas
        palavras_termo = termo.split()
        for palavra in palavras_termo:
            if palavra in _termos_genericos_gap:
                return True
        
        return False
    
    termos_faltantes = termos_faltantes_raw[
        ~termos_faltantes_raw['termo'].apply(_is_generic_term)
    ].head(10)
    
    # Pontos fortes: termos que ambos t√™m
    pontos_fortes = df_analise[
        (df_analise['peso_vaga'] > 0) & (df_analise['peso_cv'] > 0)
    ].sort_values(by='peso_cv', ascending=False).head(8)
    
    # Plano de a√ß√£o
    plano = []
    
    if score_final >= 70:
        plano.append("üèÜ Excelente compatibilidade! Seu perfil est√° bem alinhado com o cargo. Foque em se preparar para entrevistas comportamentais.")
    elif score_final >= 50:
        plano.append("‚ö†Ô∏è Boa base, mas pode melhorar. Adicione as palavras-chave faltantes no seu perfil para aumentar suas chances nos filtros autom√°ticos.")
    elif score_final >= 30:
        plano.append("üî∂ Compatibilidade moderada. Seu perfil precisa de ajustes para passar pelos filtros ATS. Revise as palavras-chave e experi√™ncias.")
    else:
        plano.append("‚ùå Risco de elimina√ß√£o autom√°tica. Seu perfil precisa de uma revis√£o estrutural para este cargo.")
    
    if not termos_faltantes.empty:
        lista_gaps = termos_faltantes['termo'].tolist()
        plano.append(
            f"üîç Palavras-chave ausentes no seu perfil: **{', '.join(lista_gaps[:7]).upper()}**. "
            f"Tente inclu√≠-las no Resumo, Compet√™ncias ou Experi√™ncia."
        )
    
    return {
        "score": score_final,
        "pontos_fortes": pontos_fortes['termo'].tolist(),
        "gaps_identificados": termos_faltantes['termo'].tolist(),
        "plano_acao": plano
    }


def _analisar_com_llm(client, cv_texto: str, cargo_alvo: str) -> Optional[Dict]:
    """
    Analisa CV usando LLM (GPT-4o) para an√°lise contextual inteligente.
    
    Substitui a an√°lise TF-IDF quando o client OpenAI est√° dispon√≠vel.
    A LLM entende contexto, sin√¥nimos e varia√ß√µes, gerando gaps e pontos fortes
    mais relevantes e espec√≠ficos.
    
    Args:
        client: Cliente OpenAI inicializado
        cv_texto: Texto completo do CV
        cargo_alvo: Cargo para o qual est√° se candidatando
        
    Returns:
        Dict com score, pontos_fortes, gaps_identificados, plano_acao ou None em caso de erro
    """
    logger.info(f"Analisando CV com LLM para cargo: {cargo_alvo}")
    
    # Prompt engineering baseado nas regras de ouro do problema
    msgs = [
        {"role": "system", "content": (
            "Voc√™ √© um Especialista S√™nior em ATS (Applicant Tracking System) e Recrutamento Tech.\n\n"
            "Sua miss√£o √© analisar o CV do candidato em compara√ß√£o com as expectativas REAIS do cargo informado.\n\n"
            "REGRAS DE OURO:\n\n"
            "1. **Pontos Fortes**: Liste APENAS Hard Skills, Ferramentas (Software), Metodologias espec√≠ficas e "
            "M√©tricas de Neg√≥cio que o candidato REALMENTE demonstra no CV.\n"
            "   - ‚úÖ INCLUIR: Salesforce, HubSpot, Power BI, Tableau, SQL, Python, Scrum, OKRs, pipeline management, B2B SaaS, m√©tricas espec√≠ficas\n"
            "   - ‚ùå N√ÉO INCLUIR: termos gen√©ricos como 'gest√£o', 'vendas', 'lideran√ßa', 'comunica√ß√£o', 'dados'\n\n"
            "2. **Gaps**: Liste APENAS Hard Skills, Ferramentas e Certifica√ß√µes que s√£o padr√£o OBRIGAT√ìRIO "
            "para o cargo no mercado real.\n"
            "   - ‚úÖ INCLUIR: Ferramentas espec√≠ficas faltantes (Tableau, Looker, Marketo), certifica√ß√µes relevantes (PMP, AWS), SQL avan√ßado, ABM\n"
            "   - ‚ùå N√ÉO INCLUIR: stopwords ('T√âCNICOS', 'PREVIS√ÉO', 'DESEMPENHO', 'INTEGRA√á√ÉO'), verbos gen√©ricos, "
            "erros de tradu√ß√£o, fragmentos sem contexto ('RATE', 'RATE TAXA', 'BI' isolado), n-grams gen√©ricos\n\n"
            "3. **Considere Sin√¥nimos e Varia√ß√µes**:\n"
            "   - 'BI' = 'Power BI' = 'Business Intelligence'\n"
            "   - 'automa√ß√£o de marketing' pode cobrir 'Marketing Automation'\n"
            "   - Avalie contextualmente ‚Äî se o CV menciona algo relacionado, n√£o marque como gap\n\n"
            "4. **Score (0-100)**: Avalie considerando:\n"
            "   - Presen√ßa de ferramentas espec√≠ficas: 40%\n"
            "   - M√©tricas quantific√°veis: 20%\n"
            "   - Alinhamento de experi√™ncia com o cargo: 20%\n"
            "   - Formata√ß√£o ATS-friendly: 10%\n"
            "   - Keywords estrat√©gicas: 10%\n\n"
            "5. **Plano de A√ß√£o**: D√™ 2-3 recomenda√ß√µes pr√°ticas e espec√≠ficas, come√ßando com emoji relevante "
            "(üîç, ‚ö†Ô∏è, üèÜ, ‚ùå, üî∂ dependendo do score).\n\n"
            "RESPONDA APENAS COM UM JSON V√ÅLIDO (sem markdown, sem explica√ß√µes extras):\n"
            "```json\n"
            # Exemplo de JSON esperado (mantido inline para clareza do prompt)
            "{\n"
            '    "score": 65.0,\n'
            '    "pontos_fortes": ["Salesforce", "HubSpot", "Power BI", "pipeline management", "B2B SaaS"],\n'
            '    "gaps_identificados": ["Tableau", "Looker", "SQL avan√ßado", "Marketo", "ABM"],\n'
            '    "plano_acao": ["üîç Palavras-chave ausentes...", "‚ö†Ô∏è Boa base, mas..."]\n'
            "}\n"
            "```"
        )},
        {"role": "user", "content": (
            f"CARGO ALVO: {cargo_alvo}\n\n"
            f"CV DO CANDIDATO:\n{cv_texto[:8000]}\n\n"  # Limitar a ~8000 chars (evita contextos muito grandes)
            f"Analise este CV para o cargo '{cargo_alvo}' e retorne o JSON conforme as regras."
        )}
    ]
    
    # Chamar LLM com m√°xima consist√™ncia
    resposta = chamar_gpt(client, msgs, temperature=0.2, seed=42)
    
    if not resposta:
        logger.warning("Falha ao obter resposta da LLM")
        return None
    
    # Parse do JSON da resposta
    try:
        # A resposta pode vir com blocos ```json ou JSON puro
        resposta_limpa = resposta.strip()
        
        # Remover blocos markdown se existirem
        if resposta_limpa.startswith("```json"):
            resposta_limpa = resposta_limpa.split("```json", 1)[1]
            resposta_limpa = resposta_limpa.rsplit("```", 1)[0]
        elif resposta_limpa.startswith("```"):
            resposta_limpa = resposta_limpa.split("```", 1)[1]
            resposta_limpa = resposta_limpa.rsplit("```", 1)[0]
        
        resposta_limpa = resposta_limpa.strip()
        
        # Parse do JSON
        resultado = json.loads(resposta_limpa)
        
        # Validar estrutura esperada
        if not all(k in resultado for k in ['score', 'pontos_fortes', 'gaps_identificados', 'plano_acao']):
            logger.error("Resposta LLM n√£o cont√©m todas as chaves esperadas")
            return None
        
        # Validar tipos
        if not isinstance(resultado['score'], (int, float)):
            logger.error("Score n√£o √© num√©rico")
            return None
        if not isinstance(resultado['pontos_fortes'], list):
            logger.error("pontos_fortes n√£o √© lista")
            return None
        if not isinstance(resultado['gaps_identificados'], list):
            logger.error("gaps_identificados n√£o √© lista")
            return None
        if not isinstance(resultado['plano_acao'], list):
            logger.error("plano_acao n√£o √© lista")
            return None
        
        logger.info(f"An√°lise LLM conclu√≠da com sucesso. Score: {resultado['score']}")
        return resultado
        
    except json.JSONDecodeError as e:
        logger.error(f"Erro ao fazer parse do JSON da LLM: {e}")
        logger.debug(f"Resposta recebida: {resposta[:500]}")
        return None
    except Exception as e:
        logger.error(f"Erro inesperado ao processar resposta da LLM: {e}", exc_info=True)
        return None


def buscar_variacoes_cargo(client, cargo: str) -> List[str]:
    """
    Usa IA para encontrar varia√ß√µes REAIS de mercado de um cargo.
    """
    logger.info(f"Buscando varia√ß√µes de mercado para: {cargo}")
    
    msgs = [
        {"role": "system", "content": (
            "Voc√™ √© um especialista em recrutamento no Brasil e mercado de trabalho. "
            "Dado um cargo, liste entre 5 e 8 varia√ß√µes REAIS desse cargo como aparecem "
            "em vagas publicadas no LinkedIn, Gupy, Catho e Indeed. "
            "Inclua varia√ß√µes em portugu√™s E ingl√™s que recrutadores REALMENTE usam. "
            "Mantenha o mesmo n√≠vel hier√°rquico (se √© gerente, liste cargos de ger√™ncia). "
            "N√ÉO invente cargos ‚Äî liste apenas os que EXISTEM no mercado real. "
            "Responda APENAS com a lista, um cargo por linha, sem numera√ß√£o nem explica√ß√£o."
        )},
        {"role": "user", "content": f"Cargo: {cargo}"}
    ]
    
    resposta = chamar_gpt(client, msgs, temperature=0.3, seed=42)
    
    if not resposta:
        logger.warning("Falha ao buscar varia√ß√µes ‚Äî usando cargo original")
        return [cargo]
    
    variacoes = [v.strip() for v in resposta.strip().split('\n') if v.strip()]
    if cargo not in variacoes:
        variacoes.insert(0, cargo)
    
    logger.info(f"Varia√ß√µes encontradas: {variacoes}")
    return variacoes


def gerar_job_description(client, cargo: str) -> Optional[str]:
    """
    Gera uma Job Description focada em TERMOS T√âCNICOS reais do cargo,
    sem exemplos gen√©ricos que contaminam a an√°lise.
    """
    logger.info(f"Gerando Job Description t√©cnica para: {cargo}")
    
    variacoes = buscar_variacoes_cargo(client, cargo)
    variacoes_texto = "\n".join(f"- {v}" for v in variacoes)
    
    msgs = [
        {"role": "system", "content": (
            "Voc√™ √© um especialista em recrutamento t√©cnico e sistemas ATS no Brasil.\n\n"
            "Gere uma Job Description para o cargo informado focada EXCLUSIVAMENTE em:\n"
            "- Ferramentas e softwares ESPEC√çFICOS da √°rea desse cargo\n"
            "- Metodologias e frameworks REALMENTE usados nesse cargo\n"
            "- Siglas e termos t√©cnicos ESPEC√çFICOS dessa fun√ß√£o\n"
            "- Certifica√ß√µes relevantes APENAS para esse cargo\n"
            "- Tecnologias REALMENTE exigidas nessa fun√ß√£o\n"
            "- Conceitos t√©cnicos ESPEC√çFICOS dessa √°rea\n\n"
            "REGRAS CR√çTICAS:\n"
            "- N√ÉO inclua termos gen√©ricos de outras √°reas\n"
            "- N√ÉO use exemplos que n√£o sejam da √°rea do cargo\n"
            "- N√ÉO inclua ferramentas/metodologias irrelevantes para a fun√ß√£o\n"
            "- Cada termo mencionado deve ser algo que um recrutador REALMENTE "
            "buscaria ao filtrar candidatos para ESSE cargo espec√≠fico\n"
            "- N√ÉO use verbos gen√©ricos como 'desenvolver', 'gerenciar', 'implementar'\n"
            "- N√ÉO use frases gen√©ricas como 'trabalho em equipe', 'boa comunica√ß√£o'\n\n"
            "A JD deve cobrir o cargo principal E suas varia√ß√µes de mercado.\n"
            "Inclua termos em portugu√™s E ingl√™s.\n"
            "Responda APENAS com a Job Description, sem introdu√ß√£o."
        )},
        {"role": "user", "content": (
            f"Cargo principal: {cargo}\n\n"
            f"Varia√ß√µes de mercado:\n{variacoes_texto}\n\n"
            f"Gere a Job Description T√âCNICA cobrindo APENAS termos relevantes "
            f"para esse cargo espec√≠fico e suas varia√ß√µes."
        )}
    ]
    
    jd = chamar_gpt(client, msgs, temperature=0.3, seed=42)
    
    if jd:
        logger.info(f"JD t√©cnica gerada ({len(jd)} chars)")
    else:
        logger.error("Falha ao gerar JD")
    
    return jd


def extrair_cargo_do_cv(client, cv_texto: str) -> Optional[str]:
    """
    Extrai o cargo atual/mais recente do candidato a partir do CV.
    """
    logger.info("Extraindo cargo atual do CV")
    
    msgs = [
        {"role": "system", "content": (
            "Analise o CV abaixo e identifique o cargo ATUAL ou MAIS RECENTE do candidato. "
            "Responda APENAS com o nome do cargo, nada mais. "
            "Exemplo de resposta: Gerente de Vendas"
        )},
        {"role": "user", "content": f"CV:\n{cv_texto[:3000]}"}
    ]
    
    cargo = chamar_gpt(client, msgs, temperature=0.1, seed=42)
    
    if cargo:
        cargo = cargo.strip().strip('"').strip("'")
        logger.info(f"Cargo extra√≠do: {cargo}")
    else:
        logger.error("Falha ao extrair cargo do CV")
    
    return cargo


def calcular_score_ats(cv_texto: str, cargo_alvo: str, client=None) -> Dict:
    """
    Calcula Score ATS completo com an√°lise de gaps t√©cnicos.
    
    v4.0: Usa LLM quando client dispon√≠vel, sen√£o fallback para TF-IDF.
    
    Args:
        cv_texto: Texto completo do CV
        cargo_alvo: Cargo para gerar a Job Description
        client: Cliente OpenAI (opcional, mas recomendado para an√°lise LLM)
        
    Returns:
        Dict com score_total, percentual, nivel, pontos_fortes,
        gaps_identificados, plano_acao e detalhes
    """
    logger.info(f"Calculando score ATS para cargo: {cargo_alvo}")
    
    # ‚îÄ‚îÄ‚îÄ TENTATIVA 1: An√°lise LLM (v4.0) ‚îÄ‚îÄ‚îÄ
    if client:
        logger.info("Client OpenAI dispon√≠vel - usando an√°lise LLM (v4.0)")
        analise_llm = _analisar_com_llm(client, cv_texto, cargo_alvo)
        
        if analise_llm:
            # Usar resultado da LLM
            score = analise_llm['score']
            nivel = classificar_score(score)
            
            logger.info(f"An√°lise LLM bem-sucedida. Score: {score}/100 ({nivel})")
            
            return {
                'score_total': score,
                'max_score': 100,
                'percentual': score,
                'nivel': nivel,
                'cargo_avaliado': cargo_alvo,
                'pontos_fortes': analise_llm['pontos_fortes'],
                'gaps_identificados': analise_llm['gaps_identificados'],
                'plano_acao': analise_llm['plano_acao'],
                'jd_gerada': True,
                'detalhes': {
                    'metodo': 'LLM Contextual Analysis (v4.0)',
                    'modelo': 'GPT-4o',
                    'fallback': False,
                    # Compatibilidade com UI existente - campos vazios mas presentes
                    'secoes': {'score': 0, 'encontradas': 0, 'total': 0},
                    'keywords': {'score': 0, 'encontradas': 0, 'total': 0, 'faltando': []},
                    'metricas': {'score': 0, 'quantidade': 0},
                    'formatacao': {'score': 0, 'bullets': 0, 'datas': 0},
                    'tamanho': {'score': 0, 'palavras': 0, 'ideal': 'N/A'},
                }
            }
        else:
            logger.warning("An√°lise LLM falhou - caindo para fallback TF-IDF")
    else:
        logger.info("Client OpenAI n√£o dispon√≠vel - usando fallback TF-IDF (v3.2)")
    
    # ‚îÄ‚îÄ‚îÄ FALLBACK: An√°lise TF-IDF (v3.2) ‚îÄ‚îÄ‚îÄ
    job_description = None
    if client:
        job_description = gerar_job_description(client, cargo_alvo)
    
    if not job_description:
        logger.warning("Usando JD simplificada")
        job_description = (
            f"Vaga para {cargo_alvo}. "
            f"Requisitos: experi√™ncia na √°rea, habilidades t√©cnicas relevantes, "
            f"capacidade de trabalho em equipe, boa comunica√ß√£o, "
            f"resultados mensur√°veis, gest√£o de projetos, lideran√ßa, "
            f"an√°lise de dados, planejamento estrat√©gico."
        )
    
    analise = _analisar_compatibilidade(cv_texto, job_description)
    
    score = analise['score']
    nivel = classificar_score(score)
    
    resultado = {
        'score_total': score,
        'max_score': 100,
        'percentual': score,
        'nivel': nivel,
        'cargo_avaliado': cargo_alvo,
        'pontos_fortes': analise['pontos_fortes'],
        'gaps_identificados': analise['gaps_identificados'],
        'plano_acao': analise['plano_acao'],
        'jd_gerada': job_description is not None,
        'detalhes': {
            'metodo': 'TF-IDF + Cosine Similarity (v3.2 - Fallback)',
            'ngrams': '1-3',
            'stopwords': 'NLTK (PT + EN) + Custom CV/JD (~550+)',
            'fallback': True,
        }
    }
    
    logger.info(f"Score ATS: {score}/100 ({nivel})")
    return resultado


def classificar_score(score: float) -> str:
    """Classifica o score ATS em n√≠veis qualitativos."""
    if score >= 70:
        return "Excelente"
    elif score >= 50:
        return "Bom"
    elif score >= 30:
        return "Regular"
    else:
        return "Precisa Melhorar"
